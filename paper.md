# ocr_kor
딥러닝을 활용한 한글문장 OCR연구

## 1.Introduction
광학 문자 인식 OCR(Optical Character Recognition)은 사람이 쓰거나 기계로 인쇄한 문자의 영상을 이미지 스캐너로 획득하여 기계가 읽을 수 있는 문자로 변환하는 것이다. 회사 및 관공서의 계약서 및 서류 문서들은 지금까지도 인쇄물로서 보관되는 곳이 많다. 이러한 정보자산들의  디지털화에 있어서 가장 필요하고도 중요한 기술이 바로 OCR이다. 그러나 오픈소스를 포함한 상용 OCR 엔진은 영문에 초점이 맞춰져 있어 한글 문서에 적용할 수 있는  기술연구가 필요하다. 
OCR 기술은 크게 text detection과 text recognition으로 구성되어 있고 OCR 기술이 어려운 점은 크게 3가지로 정리된다. 첫째, 문서 이미지 속 글자들은 정형화되어 있지만, 손글씨 및 서명은 비정형화되어 있어 분별이 어렵다. 둘째, 배경이 복잡한 경우 문자의 구분이 힘들다. 그리고 다양한 간섭요소, 예를 들면 노이즈, 왜곡, 글자 사이 밀도, 저해상도로 인해 식별에 어려움이 있다. [1]    
한글에 대한 OCR이 더 어려운 이유는 영문과 비교해 분류해야 할 글자 수가 실험기준으로 (26 → 900) 35배 정도 차이가 나 정확도를 높이는데 어려움이 있다. 이전까지의 한글 OCR 연구는 글자 단위에 초점이 맞춰져 있었다. 또한 사용된 모델구조 역시 CNN(Convolutional Neural Network) 나 RNN(Recurrent Neural Network) 와 같이 단일 모델로만 구성되어 있어 성능을 높이는 데 한계가 있었다.  기존 문자탐지 모델의 바이너리 맵을 분석해본 결과 문자가 존재할 영역을 글자 단위별로 정확히 인식하였고 글자사이 여백에 대한 분류를 통해 단어 간 분류까지 가능했다. 따라서 OCR 성능을 높이기 위해서 문자인식 부분에 초점을 맞추어 연구 방향을 설정하였다. 
본 논문에서는 기존 영문 문자인식 모델조합을 찾는 데 사용된 4단계 STR(Scene Text Recognition) 모델구조(변환, 추출, 시퀀스, 예측)를 사용해 실험을 진행하였다. 또한 실험을 위한 데이터 세트를 한국어 학습용 어휘목록과 한글 폰트를 사용해 직접 생성하여 진행하였다.  
논문의 구성은 OCR 관련 이전연구에 대해 모듈별로 주요특성을 살펴보고 한글 문자인식 모델조합을 찾는 딥러닝 모델 구성, 실험구현 상세과정에 관해 설명한다. 마지막으로 실험결과에 대한 분석과 결과를 정리했다.  

## 2.Recent Advances in Scene Text Detection and Recognition
### 2.1 text detection
기존의 문자탐지는 글자/단어 후보생성→ 후보 필터링 → 그룹화와 같은 여러 단계로 나누어져 있었다. 따라서 모델 학습 중의 튜닝이 어려웠고, 완성된 모델의 속도도 느려서 실시간 탐지에 적용하기 힘들었다. Textboxes [2]는 물체 감 지에서큰성능향상을보여준SSD [3]논문을본떠만들었 으며, 단일 네트워크로 구성되어 있기 때문에 기존의 모델 들에 비해 현저히 빠른 성능과 정확도 향상을 보였다. 그러 나 Textboxes는 문자와 비문자 그리고 경계 박스에 대한 회 귀분석방식이다보니각이미지가매우가깝게자리잡고 있다면 문자와 비문자를 구별하기가 힘들다. 이를 개선하 기 위해 나온 방법이 의미 분할 (semantic segmentation) 방법 이다.이방법은분할의기본단위를클래스로하여같은클 래스에 해당하는 사물을 예측하고 마스크 상에 동일한 색 상으로 표시하는 방법이다. PixelLink [4] 에서 사용한 인스 턴스 분할 (instance segmentation)은 분할의 기본 단위를 사 물로 하여, 동일한 클래스에 해당하더라도 서로 다른 사물 에해당하면이들을예측마스크상에다른색상으로표시 한다. PixelLink는 위치회귀(location regression) 없이 텍스트 박스에서 직접 분할결과를 추출해 더 적은 수용영역이 필 요하고, 이러한 부분은 학습을 더 쉽게 만든다. FOTS (Fast Oriented Text Spotting) [5]는 종단 간 접근방식 을 적용해 탐지와 인식 모듈이 동시에 훈련됨으로써 상승 한인식결과가다시탐지모듈의정확도를높이는효과를 가져온다.  
### 2.2 text recognition
문자인식 부분에서는 특성을 추출하는 CNN과 시계열 모 델인 RNN을 통합하여 하나의 통일된 네트워크 구조의 CRNN [6]이 제안되었다. CRNN은 먼저 CNN을 통해 입력 이미지로부터 특성 시퀀스를 추출하고 이 특성 시퀀스들을 RNN의 입력값으로 하여 이미지의 텍스트 시퀀스를 예측 한다. 예측된 텍스트 시퀀스를 텍스트로 변환하여 결과를 출력한다. 이 모델은 미리 정해진 어휘에 제한되지 않고, 임 의길이의시계열데이터를다룰수있는특징이있다.
GRCNN (Gated Recurrent Convolution Neural Network) [7] 은 recurrent convolution 레이어에 있는 컨텍스트 모듈을 제 어하기 위해 RCNN 에 게이트가 더해진 모델이다. 게이트 (gate)는 컨텍스트 모듈 제어뿐만 아니라 CNN의 정보와 RNN의 정보를 균형 있게 제어하는 역할을 한다.
특성 영역과 타깃 사이의 정확한 alignment를 얻지 못하는 현상을 어텐션 드리프트(Attention drift)라고 한다. FAN (Focusing Attention Network) [8] 은 이러한 문제를 해결하기 위해 고안된 방법으로 2가지 요소로 구성된다. 먼저 어텐 션 네트워크는 글자 타깃을 인식하는 데 사용되고 포커싱 네트워크는 어텐션 네트워크가 타깃 지역에 적절히 어텐션 을 갖는지 측정해서 어텐션을 조절하는 역할을 한다.
조금은 다른 접근방식으로 문자인식 모델들의 비교에서 잘못된 부분을 분석한 논문도 있다. 해당 논문 [9] 에서는 훈련 데이터 세트와 평가 데이터 세트가 일치하지 않음으 로써 성능에서 차이가 발생하는 것을 증명하고 STR(Scene Text Recognition)의 구조를 사용하여 모듈조합 간 성능 비 교분석을 진행했다.  
### 2.3 end to end text recognition
Aster (Attentional Scene Text Recognizer with Flexible Rectification) [10] 는 교정 네트워크와 인식 네트워크를 종 단 간으로 연결하는 모델이다. 교정 네트워크는 입력 이미 지를 새로운 이미지로 적응적으로 변환하여 이미지 속 기 울어지거나 왜곡된 텍스트를 교정한다. 인식 네트워크는 어텐션 기반의 seq2seq 모델로 변환된 이미지로부터 글자 시퀀스를 예측한다.
문자탐지와 문자인식은 서로 상이함으로 인해 최적화의 어려움이 있어 통합된 구조로 만들기 어려웠다. TextSpotter [11] 는 text-alignment 레이어와 캐릭터 어텐션 메커니즘을 사용하여 통합 구조를 만들었다. 문자탐지와 문자인식두개모듈의통합은서로컨볼루션특성을공유 함으로써 상호보완적으로 작동하고 종단 간으로 훈련이 가 능하여 더 높은 성능을 보인다.
Tesseract OCR [12] 엔진은 상업용 OCR 엔진의 성능을 개 선하기 위해 1985년 HP사 연구소에서 시작된 OCR 오픈소
스이다. 최근 릴리즈된 버전은 LSTM (Long Short-Term Memory models) 기반의 버전까지 출시되었으며 100개 이 상의 언어를 지원한다. 하지만 한글 OCR 성능은 정확도가 낮아 실제 애플리케이션에 적용하기가 힘들다는 한계가 있 다.  
### 2.4 한글 OCR 이전연구
한글에 대한 OCR 이전연구로는 이미지 프로세싱을 통해 이미지에서 글자영역을 추출하고, 이를 학습 데이터로 활 용한 딥러닝으로 한글 OCR의 정확도를 향상하는 방법을 제안한 연구가 있다. [13] 한글의 초성, 중성, 종성의 모든 경우의 수를 조합하여 글자의 이미지를 생성, 그 이미지를 CNN을 이용해 딥러닝으로 학습시킨다. 다른 연구로는 한 글 필기체 인식 문제에서 펜촉의 움직임 정보를 기반으로 하는 온라인 방식의 해법 체계를 정리하고, RNN 기반의 딥 러닝기법의가능성을예비실험을통해확인한결과를정 리한연구가있다. [14]조합가능한모든한글글자이미지 를 생성하거나 SERI95a, PE92 데이터 세트를 사용하였으나 글자 단위로만 진행되어 한계를 가진다.  
  
## 3. 한글문서 OCR을 위한 딥러닝 모델 구성
### 3.1 문자탐지 부분과 문자인식 부분의 비교
그림1은글자단위문자탐지모델을사용했을때생성되는 글자 스코어 맵과(왼쪽) 글자 사이 여백을 표시하는 어피니 티맵(오른쪽) 이다. 그림 1에서보는것과같이문자영역 을 정확히 인식하였으며, 글자뿐만 아니라 글자 사이 간격 까지찾아내하나의단어는동일한바운딩박스안에포함 되는모습을그림2에서확인할수있다.
글자영역을 찾는 것보다 찾은 글자영역을 바탕으로 정확 한 글자를 인식하는 것이 한글 문장의 OCR 성능을 높이는 데 주요하다고 판단하여 문자인식 모델에 중점을 두어 이 후 실험을 진행했다.  
### 3.2 모델구조
OCR을 위한 딥러닝 모델은 STR(Scene Text Recognition)의 구조를 가져와서 변환, 특성추출, 시퀀스, 예측 4개 모듈로 구성되어있다.
변환 모듈은 TPS (Thin Plate Spline) 변환 사용 여부에 따라 모듈이 구분된다. TPS 변환은 데이터 보간 및 평활화를 위 한스플라인기반기술로이미지속문자가기울거나왜곡 되어있는 경우 바로잡아 표준화된 이미지로 만드는 역할을 한다.
특성추출 모듈은 이미지에서 시각적 특성을 추출하는 부 분으로 VGGNet, RCNN, ResNet 모델을 각각 사용하였다. VGGNet은 간단한 구조와 단일 네트워크에서 좋은 성능을 보여준다는 이유로 많은 네트워크에서 응용되고 있다. RCNN은 이미지 분류를 수행하는 CNN과 이미지에서 물체 가 존재할 영역을 제안해주는 region proposal 알고리즘을 연결하여 높은 성능의 물체탐지를 가능하게 하는 모델이 다. ResNet은 망이 깊어지는 경우 발생하는 그래디언트 소 멸/폭발 부작용을 해결하기 위해 레이어의 입력을 레이어 의 출력에 바로 연결하게 하는 스킵 커넥션 (skip connection)을 사용한 모델이다.
시퀀스 모델부분은 BiLSTM 사용 여부에 따라 모듈이 구 분된다. BiLSTM은 앞에서 뒤, 뒤에서 앞, 모두 고려하는 양방향(bidirectional) 네트워크를 통해 LSTM의 성능 개선을 가능하게 한다.
예측 모듈은 CTC(Connectionist Temporal Classification)와 어텐션으로 모듈이 구분된다. CTC는 학습데이터에 클래스 라벨만순서대로있고각클래스의위치는어디있는지모 르는 분할되지 않은 시퀀스 데이터의 학습을 위해서 사용 하는 알고리즘이다. 문장 길이가 길고 층이 깊으면, 인코더 가 압축해야 할 정보가 많아 정보 손실이 일어나고, 디코더 는 인코더가 압축한 정보를 초반 예측에만 사용하는 경향 을 보인다. 이 때문에 인코더-디코더 사이에 병목현상이 발 생하고이에디코더예측때가장의미있는인코더입력에 주목하게 만드는 어텐션 메커니즘이 제안되었다.
앞서언급된4개모듈조합은전체경우의수가 2x3x2x 2 = 24가지가나와한글문장에가장적합한모듈조합을찾 고자 모든조합에 대한 실험을 진행했다.  
  
## 4. 실험
### 4.1 데이터세트
한글 문장 OCR과 관련하여 공개된 데이터 세트가 없어 딥 러닝모델을훈련하기위해선한글문장데이터세트를직 접 생성할 필요가 있었다. 데이터 세트를 생성하는 과정은 크게 다음과 같다. 1) 단어 사전에서 랜덤으로 단어를 선정 2) 한글 폰트 파일과 배경 3종(가우시안 노이즈, 순백색, Quasi crystal) 준비 3) 기본, 배경, 기울기, 왜곡, 흐리게 한 5 가지종류의한글문장데이터세트생성.
한글 폰트는 네이버 나눔 글꼴(23종) [15] 과 폰트 코리아 (76종) 폰트 [16] 총 99종을 준비했다. 한글 단어 사전은 총 5,965개의 단어와 974개 글자를 포함한 국립국어원의 한국 어 학습용 어휘목록 [17] 을 사용했다. 그리고 문서 파일에 서 가능한 변형으로 (기울기, 왜곡, 흐리게 하기, 배경 포함) 을선택하였고,한개문장데이터가포함하는단어의수는 10개로설정후그림3과같은문장데이터를생성했다.훈 련데이터는 기본과 기울기 데이터를 각각 9,000개 포함하 고 검증데이터는 왜곡, 흐리게 하기, 배경 포함 데이터를 각 각 3,000개로 맞춰 훈련데이터와 검증데이터 비율을 2:1로 구성했다. 테스트 데이터 세트는 직접 생성한 5가지 종류 (기본,기울기,왜곡,흐리게하기,배경포함)의데이터세 트 2,700개 문장과 최근 공개된 AI 오픈 이노베이션 허브의 한국어 글자체 이미지 AI 데이터 [18] 중 인쇄체 현대 한글 6만자,단어3만자를사용했다.  
### 4.2 모델조합 비교
정확한성능측정을위해모델조합별로3번씩훈련을수행 하였고 3번 결괏값의 평균값으로 정확도와 추론 시간, 파라 미터 복잡도를 측정했다. 예측모델의 종류에 따라 예측모 델이 CTC인 경우에는 CTC 로스를 어텐션인 경우에는 크 로스엔트로피 로스를 사용해 정확도를 계산하였다. 정확도 와 함께 Nltk 모듈에서 제공하는 edit_distance를 사용해서 두 문장 간의 유사도를 따로 표시했다.
실험 결과를 살펴보면 그림 4는 모델조합별 시간과 정확도 의관계를그림5는파라미터수와정확도의관계를나타내 고 있다. 표 1은 그림 4에서 경계의 끝에 위치해 좋은 성능 을보이는5개모델조합을상세히나타낸표이다.표2는그 림 5에서 경계의 끝에 위치해 좋은 성능을 보이는 5개 모델 조합을 상세히 나타낸 표이다.
가장 높은 정확도를 보인 모델조합은 TPS VGG BiLSTM Attn이다. 변환 모듈에서는 TPS(Thin Plate Spline)를 사용 할 때에 정확도가 향상되었으며, 추출 모듈에서는 VGG와 ResNet이 다소 성능이 높게 나왔다. 시퀀스 모듈과 예측 모듈은 BiLSTM과 어텐션 조합의 모델이 시퀀스 모듈없음 과 CTC 조합의 모델에 비해 정확도에서 크게는 20% 차이 가 발생했다. BiLSTM 과 어텐션 조합이 높은 성능을 내는 이유로 모든 파라미터가 동시에 학습되는 종단 간 학습과 분산표상 사용을 꼽는다.  
### 4.3 실험환경
파이토치로 구현되어있는 문자인식 모델과 텐서플로우로 구현되어있는 문자인식 학습 데이터 생성 모델 소스를 베 이스라인으로 구성하였다. 두 개의 오픈소스 모두 영문을 기반으로 작성되어있어 한글에 맞춰 동작할 수 있도록 변 환 작업이 필요했다. 배치 사이즈는 192로, 반복 횟수는 300,000회, Adam Optimizer의 베타 값은 0.9, Adadelta의 decay rate는 0.95, eps는 1e-8 로 설정했다. 모델실험은 Tesla P40 * 2대와 GeForce GTX 1080 Ti * 4대로 3주간 진행하였 다.
  
## 5. Conclusion
한글에 대한 OCR 연구는 그 중요성에 비해 다양한 연구 가 진행되지 않았다. OCR 모듈별로 주요 특징을 정리해보 고한글문자인식에적합한딥러닝모델조합을찾는실험 을 진행했다. 실제 애플리케이션에 적용 가능성을 높이고 자한글문장OCR데이터를문서에서발견되는형태로직 접 생성하였다. 한글 문장에 적합한 모델 조합은 TPS VGG BiLSTM Attn 이 다른 모델 조합에 비해 높은 정확도를 보였 다. 정확도 향상으로 실제 서비스에 사용하려면 최근 주목 받는 트랜스포머, 버트 모델을 고려해볼 만하다.
## 6. References




